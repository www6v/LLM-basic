{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de567b33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T14:27:15.033799Z",
     "start_time": "2024-01-24T14:27:15.027876Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809ef5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T14:31:01.137756Z",
     "start_time": "2024-01-24T14:31:01.132032Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9335b",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83112a56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:49:49.021178Z",
     "start_time": "2024-01-28T01:49:43.173261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-28 09:49:45,537] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import DPOTrainer\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef82128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:49:49.453635Z",
     "start_time": "2024-01-28T01:49:49.450163Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "new_model = \"NeuralHermes-2.5-Mistral-7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b507403f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:49:50.651611Z",
     "start_time": "2024-01-28T01:49:50.646935Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b76407",
   "metadata": {},
   "source": [
    "## dpo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e608e297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:50:05.363555Z",
     "start_time": "2024-01-28T01:49:51.904209Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Intel/orca_dpo_pairs\")['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59c7a2",
   "metadata": {},
   "source": [
    "### basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4201d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:51:11.525012Z",
     "start_time": "2024-01-28T01:51:11.517548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['system', 'question', 'chosen', 'rejected'],\n",
       "    num_rows: 12859\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0c82dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:10:40.839183Z",
     "start_time": "2024-01-28T02:10:40.831398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system', 'question', 'chosen', 'rejected']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a2c30f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T01:50:47.862060Z",
     "start_time": "2024-01-28T01:50:47.853885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given a definition of a task first, then some input of the task.\n",
      "This task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\n",
      "\n",
      "AFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc94cf4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:11:22.898509Z",
     "start_time": "2024-01-28T02:11:22.892653Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(dataset[0]['chosen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a69763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:11:21.678810Z",
     "start_time": "2024-01-28T02:11:21.673002Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(dataset[0]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac4a25",
   "metadata": {},
   "source": [
    "### format to chatml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e004365",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/transformers/chat_templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "503bd506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:16:39.624593Z",
     "start_time": "2024-01-28T02:16:39.615827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system', 'question', 'chosen', 'rejected']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_columns = dataset.column_names\n",
    "original_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d5dcd9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:13:00.314606Z",
     "start_time": "2024-01-28T02:13:00.302888Z"
    }
   },
   "outputs": [],
   "source": [
    "def chatml_format(example):\n",
    "    # Format system\n",
    "    if len(example['system']) > 0:\n",
    "        message = {\"role\": \"system\", \"content\": example['system']}\n",
    "        system = tokenizer.apply_chat_template([message], tokenize=False)\n",
    "    else:\n",
    "        system = \"\"\n",
    "\n",
    "    # Format instruction\n",
    "    message = {\"role\": \"user\", \"content\": example['question']}\n",
    "    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # Format chosen answer\n",
    "    chosen = example['chosen'] + \"<|im_end|>\\n\"\n",
    "\n",
    "    # Format rejected answer\n",
    "    rejected = example['rejected'] + \"<|im_end|>\\n\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": system + prompt,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "630b0b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:13:18.918947Z",
     "start_time": "2024-01-28T02:13:18.203176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea788fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:13:42.324888Z",
     "start_time": "2024-01-28T02:13:42.315744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>', 'eos_token': '<|im_end|>', 'unk_token': '<unk>'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cec434b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:14:19.657479Z",
     "start_time": "2024-01-28T02:14:19.650702Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e628586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:14:44.255720Z",
     "start_time": "2024-01-28T02:14:44.181551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"<|im_start|>user\\nYou will be given a definition of a task first, then some input of the task.\\nThis task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\\n\\nAFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\\nOutput:<|im_end|>\\n<|im_start|>assistant\\n\",\n",
       " 'chosen': '[\\n  [\"AFC Ajax (amateurs)\", \"has ground\", \"Sportpark De Toekomst\"],\\n  [\"Ajax Youth Academy\", \"plays at\", \"Sportpark De Toekomst\"]\\n]<|im_end|>\\n',\n",
       " 'rejected': \" Sure, I'd be happy to help! Here are the RDF triplets for the input sentence:\\n\\n[AFC Ajax (amateurs), hasGround, Sportpark De Toekomst]\\n[Ajax Youth Academy, playsAt, Sportpark De Toekomst]\\n\\nExplanation:\\n\\n* AFC Ajax (amateurs) is the subject of the first triplet, and hasGround is the predicate that describes the relationship between AFC Ajax (amateurs) and Sportpark De Toekomst.\\n* Ajax Youth Academy is the subject of the second triplet, and playsAt is the predicate that describes the relationship between Ajax Youth Academy and Sportpark De Toekomst.\\n\\nNote that there may be other possible RDF triplets that could be derived from the input sentence, but the above triplets capture the main relationships present in the sentence.<|im_end|>\\n\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatml_format(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fbf3c7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-28T02:16:44.435717Z",
     "start_time": "2024-01-28T02:16:42.019525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44d3618b9ea4bfca064008dc6b19600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12859 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    chatml_format,\n",
    "    remove_columns=original_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf753c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
