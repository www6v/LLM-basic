{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa3776c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T15:48:50.985380Z",
     "start_time": "2023-07-15T15:48:47.952070Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341189a9",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22e203e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T15:53:11.333137Z",
     "start_time": "2023-07-15T15:53:11.317864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('../imgs/grad-accumulation.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45254662",
   "metadata": {},
   "source": [
    "- 显存占用优化算法\n",
    "    - 可以在 `batch_size = 1` （或者是很小时）的时候，还能事实上提升真正的 `batch_size`\n",
    "        - `batch_size = 1` （或者很小时）会导致训练过程的不稳定，收敛更慢，精度更低；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ce161",
   "metadata": {},
   "source": [
    "### Vanilla "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7b8d28",
   "metadata": {},
   "source": [
    "```\n",
    "# loop through batches\n",
    "for (inputs, labels) in data_loader:\n",
    "\n",
    "    # extract inputs and labels\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # passes and weights update\n",
    "    with torch.set_grad_enabled(True):\n",
    "        \n",
    "        # forward pass \n",
    "        preds = model(inputs)\n",
    "        loss  = criterion(preds, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward() \n",
    "\n",
    "        # weights update\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95178d",
   "metadata": {},
   "source": [
    "### accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797fafa",
   "metadata": {},
   "source": [
    "```\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# loop through batches\n",
    "for batch_idx, (inputs, labels) in enumerate(data_loader):\n",
    "\n",
    "    # extract inputs and labels\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # passes and weights update\n",
    "    with torch.set_grad_enabled(True):\n",
    "        \n",
    "        # forward pass \n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        \n",
    "        loss /= gradient_accumulation_steps\n",
    "        \n",
    "        # backward pass => compute gradient\n",
    "        loss.backward() \n",
    "        \n",
    "        if ((batch_idx + 1) % gradient_accumulation_steps == 0) or ((batch_idx+1) == len(data_loader)):\n",
    "            # weights update\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a5502b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:02:56.427624Z",
     "start_time": "2023-07-15T16:02:56.421135Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a854b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:03:06.819422Z",
     "start_time": "2023-07-15T16:03:06.808700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(retain_graph=True)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6efae4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:03:11.100823Z",
     "start_time": "2023-07-15T16:03:11.087680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43758c9",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1fbf92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:03:55.369636Z",
     "start_time": "2023-07-15T16:03:55.362762Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install nvidia-ml-py3\n",
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    total_used = 0\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        total_used += info.used\n",
    "    print(f\"GPU memory occupied: {total_used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "391fe77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:03:57.019733Z",
     "start_time": "2023-07-15T16:03:57.011061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 13166 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbf6c9",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db00e2f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:04:20.104504Z",
     "start_time": "2023-07-15T16:04:20.067341Z"
    }
   },
   "outputs": [],
   "source": [
    "num_seqs = 1024\n",
    "seq_len = 512\n",
    "dummy_data = {\n",
    "    'input_ids': np.random.randint(100, 30000, (num_seqs, seq_len)),\n",
    "    'labels': np.random.randint(0, 2, (num_seqs))\n",
    "}\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9adee794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:04:40.737826Z",
     "start_time": "2023-07-15T16:04:40.724869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ds['labels'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a3362",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845d4c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T12:11:21.627905Z",
     "start_time": "2023-07-15T12:11:21.620079Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eff0a7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:04:50.252807Z",
     "start_time": "2023-07-15T16:04:43.674385Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-large-uncased').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b3b8458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T16:04:51.220069Z",
     "start_time": "2023-07-15T16:04:51.214221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 13166 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62260fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T12:01:47.615885Z",
     "start_time": "2023-07-15T12:01:47.615877Z"
    }
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6b1cf",
   "metadata": {},
   "source": [
    "### training args & trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc3c0e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T15:47:33.318433Z",
     "start_time": "2023-07-15T15:46:55.249745Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.set_verbosity_error()\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47c43f",
   "metadata": {},
   "source": [
    "```\n",
    "{'train_runtime': 38.0194, 'train_samples_per_second': 26.934, 'train_steps_per_second': 3.367, 'train_loss': 0.7216147780418396, 'epoch': 1.0}\n",
    "Time: 38.02\n",
    "Samples/second: 26.93\n",
    "GPU memory occupied: 21296 MB.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ad3cf",
   "metadata": {},
   "source": [
    "#### gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e54bf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-15T15:50:46.779602Z",
     "start_time": "2023-07-15T15:48:58.436823Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 102.8176, 'train_samples_per_second': 9.959, 'train_steps_per_second': 1.245, 'train_loss': 0.7096406817436218, 'epoch': 1.0}\n",
      "Time: 102.82\n",
      "Samples/second: 9.96\n",
      "GPU memory occupied: 13166 MB.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from torch.utils.data import Dataset\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    total_used = 0\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)\n",
    "        info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        total_used += info.used\n",
    "    print(f\"GPU memory occupied: {total_used//1024**2} MB.\")\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "\n",
    "num_seqs = 1024\n",
    "seq_len = 512\n",
    "dummy_data = {\n",
    "    'input_ids': np.random.randint(100, 30000, (num_seqs, seq_len)),\n",
    "    'labels': np.random.randint(0, 2, (num_seqs))\n",
    "}\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format('pt')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-large-uncased').to('cuda')\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c303d",
   "metadata": {},
   "source": [
    "```\n",
    "{'train_runtime': 102.8176, 'train_samples_per_second': 9.959, 'train_steps_per_second': 1.245, 'train_loss': 0.7096406817436218, 'epoch': 1.0}\n",
    "Time: 102.82\n",
    "Samples/second: 9.96\n",
    "GPU memory occupied: 13166 MB.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
