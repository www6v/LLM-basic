{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48febecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes datasets accelerate loralib\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git@main \n",
    "!pip install -q git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80e020b",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3891ab0",
   "metadata": {},
   "source": [
    "- bigscience/bloom-7b1\n",
    "- lora fine-tune bloom: 可插拔式的（plugin/adapter）\n",
    "    - freeeze original weights\n",
    "    - plugin lora adapters (peft)\n",
    "- huggingface transformers 库\n",
    "    - trainer.train 的参数及过程；\n",
    "    - mlm 与 clm 的差异：（都是 unsupervised learning，都可以自动地构建 input/labels）\n",
    "        - mlm：bert\n",
    "        - clm：gpt（bloom）\n",
    "    - pipeline\n",
    "        - dataset/tasks\n",
    "        - tokenizer\n",
    "        - training (fine-tune base lora)\n",
    "        - inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76dd11d",
   "metadata": {},
   "source": [
    "## base model & lora adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3acc67a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:29:01.386210Z",
     "start_time": "2023-06-04T11:28:58.475595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/whaow/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/whaow/anaconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/whaow/anaconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb \n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43585dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:29:04.743132Z",
     "start_time": "2023-06-04T11:29:04.728571Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db90920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:29:05.907887Z",
     "start_time": "2023-06-04T11:29:05.897714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch       : 2.0.0+cu118\n",
      "bitsandbytes: 0.38.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dd7c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T11:31:29.541972Z",
     "start_time": "2023-06-04T11:31:28.885611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft        : 0.4.0.dev0\n",
      "torch       : 2.0.0+cu118\n",
      "loralib     : 0.1.1\n",
      "transformers: 4.30.0.dev0\n",
      "accelerate  : 0.18.0\n",
      "datasets    : 2.11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from watermark import watermark\n",
    "print(watermark(packages='peft,torch,loralib,transformers,accelerate,datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b254b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:22:31.057466Z",
     "start_time": "2023-05-27T04:22:17.880192Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"bigscience/bloom-7b1\", \n",
    "    load_in_8bit=True, \n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-7b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40e345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:23:09.815826Z",
     "start_time": "2023-05-27T04:23:09.445309Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.config\n",
    "AutoConfig.from_pretrained(\"bigscience/bloom-7b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cab40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:23:32.904412Z",
     "start_time": "2023-05-27T04:23:32.896860Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bec88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:24:26.378420Z",
     "start_time": "2023-05-27T04:24:26.370376Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.transformer.word_embeddings\n",
    "model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205279aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:24:30.082169Z",
     "start_time": "2023-05-27T04:24:30.074968Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13451a31",
   "metadata": {},
   "source": [
    "### freeze original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c024b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:26:00.858714Z",
     "start_time": "2023-05-27T04:26:00.848057Z"
    }
   },
   "outputs": [],
   "source": [
    "list(model.parameters())[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8949b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:27:01.261630Z",
     "start_time": "2023-05-27T04:27:01.200624Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False  # freeze the model - train adapters later\n",
    "#     print(i, 'param.requires_grad = False')\n",
    "    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "        param.data = param.data.to(torch.float32)\n",
    "#         print(i, 'ndim == 1, torch.float16 to torch.float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40503a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:27:30.811647Z",
     "start_time": "2023-05-27T04:27:30.802911Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce number of stored activations\n",
    "model.gradient_checkpointing_enable()  \n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510315e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:27:49.163660Z",
     "start_time": "2023-05-27T04:27:49.154423Z"
    }
   },
   "outputs": [],
   "source": [
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x): \n",
    "        return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29087b4",
   "metadata": {},
   "source": [
    "### LoRa Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b202a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:28:12.406966Z",
     "start_time": "2023-05-27T04:28:12.400279Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860f290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:30:09.762833Z",
     "start_time": "2023-05-27T04:30:09.754680Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model \n",
    "config = LoraConfig(\n",
    "    r=16, #low rank\n",
    "    lora_alpha=32, #alpha scaling， scale lora weights/outputs\n",
    "    # target_modules=[\"q_proj\", \"v_proj\"], #if you know the \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83459bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:30:33.895170Z",
     "start_time": "2023-05-27T04:30:23.695760Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96eba17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:31:05.599257Z",
     "start_time": "2023-05-27T04:31:05.589168Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718a902",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac0ff3",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23e027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:32:24.503674Z",
     "start_time": "2023-05-27T04:32:20.544103Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Abirate/english_quotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65002e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:32:33.770607Z",
     "start_time": "2023-05-27T04:32:33.763460Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f4abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:32:48.202600Z",
     "start_time": "2023-05-27T04:32:48.194996Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d6bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:33:16.069537Z",
     "start_time": "2023-05-27T04:33:16.028446Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d23a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:33:40.816836Z",
     "start_time": "2023-05-27T04:33:40.796788Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['train']['quote'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47e7ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:33:47.492377Z",
     "start_time": "2023-05-27T04:33:47.476200Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train']['author'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e31c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:34:13.386736Z",
     "start_time": "2023-05-27T04:34:13.373650Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7805c71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:34:25.952405Z",
     "start_time": "2023-05-27T04:34:25.907838Z"
    }
   },
   "outputs": [],
   "source": [
    "str(dataset['train']['tags'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3039ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:34:54.089588Z",
     "start_time": "2023-05-27T04:34:54.073977Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge(row):\n",
    "    row['prediction'] = row['quote'] + ' ->: ' + str(row['tags'])\n",
    "    return row\n",
    "dataset['train'] = dataset['train'].map(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d8575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:34:55.999771Z",
     "start_time": "2023-05-27T04:34:55.978125Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['train']['prediction'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04286052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:35:21.871874Z",
     "start_time": "2023-05-27T04:35:21.864189Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f9dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:35:58.426014Z",
     "start_time": "2023-05-27T04:35:58.391819Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer(dataset['train']['prediction'][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9981d",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cdfe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:36:21.816424Z",
     "start_time": "2023-05-27T04:36:21.545578Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda samples: tokenizer(samples['prediction']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6cb7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:36:23.710570Z",
     "start_time": "2023-05-27T04:36:23.702652Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'input_ids', 'attention_mask'\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76445a9",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae43b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:36:57.623411Z",
     "start_time": "2023-05-27T04:36:57.281712Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86290120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:44:56.744479Z",
     "start_time": "2023-05-27T04:36:59.580379Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    train_dataset=dataset['train'],\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=4, \n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=100, \n",
    "        max_steps=200, \n",
    "        learning_rate=2e-4, \n",
    "        fp16=True,\n",
    "        logging_steps=1, \n",
    "        output_dir='outputs'\n",
    "    ),\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "model.config.use_cache = False  \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21bd50",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6f152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:45:23.617833Z",
     "start_time": "2023-05-27T04:45:15.996301Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = tokenizer(\"“Training models with PEFT and LoRa is cool” ->: \", return_tensors='pt')\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(**batch, max_new_tokens=50)\n",
    "\n",
    "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136a81d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T04:45:40.138422Z",
     "start_time": "2023-05-27T04:45:33.322302Z"
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "batch = tokenizer(\"“An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains.” ->: \", return_tensors='pt')\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(**batch, max_new_tokens=50)\n",
    "\n",
    "print('\\n\\n', tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a36375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-27T03:56:04.539665Z",
     "start_time": "2023-05-27T03:56:04.534224Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.data_collator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "218px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
