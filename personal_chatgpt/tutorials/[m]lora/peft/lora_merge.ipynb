{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b8c491-2204-4840-ac12-0cd2cfe16cbc",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://huggingface.co/blog/peft_merging\n",
    "    - https://huggingface.co/docs/peft/developer_guides/model_merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8489aa-a8df-43d3-bf0b-a98249515381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe2b24e-7458-41b4-8fde-6a86f166ac9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b7a8372-6369-4cdc-a3c8-70f46bc87e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed524676-de83-4c35-b46f-68fc16598d07",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b111c-71ea-4e37-a6f2-f6b9ed3fe354",
   "metadata": {},
   "source": [
    "- not only on LLMs, but diffusion models\n",
    "- LoraConfig\n",
    "    - target_modules: The names of the modules to apply the adapter to. \n",
    "    - r: Lora attention dimension (the \"rank\").\n",
    "    - lora_alpha: The alpha parameter for Lora scaling.\n",
    "    - fan_in_fan_out: boolean, 是否先入参再出参（维度、shape 对齐）\n",
    "        ```\n",
    "        # torch.nn.Linear, fan_in_fan_out: False\n",
    "        # y = xA^T + b\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        ```\n",
    "    - scaling: https://arxiv.org/pdf/2106.09685.pdf\n",
    "        - ∆W is scaled by α / r where α is a constant.\n",
    "        \n",
    "        ```\n",
    "        # lora.layer\n",
    "        if use_rslora:\n",
    "            self.scaling[adapter_name] = lora_alpha / math.sqrt(r)\n",
    "        else:\n",
    "            self.scaling[adapter_name] = lora_alpha / r\n",
    "        ```\n",
    "\n",
    "- W, lora_a, lora_b\n",
    "    - $\\Delta W = $  lora_b @ lora_a\n",
    "    - $(W+\\Delta W)x=Wx+(lora\\_b @ lora\\_a)x$\n",
    "- combination types\n",
    "    - ties: https://arxiv.org/pdf/2306.01708.pdf\n",
    "    - svd\n",
    "        - $\\Delta_{merged}=weight_1*scaling_1*lora\\_{b1}*lora\\_{a1} + weight_2*scaling_2*lora\\_{b2}*lora\\_{a2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "833264bf-d73e-40d3-8448-eb711c973c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EnUd1eXLvXCxRZj9NW2BeA.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EnUd1eXLvXCxRZj9NW2BeA.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c91a558-54ed-4c44-a776-0eba24fca3a2",
   "metadata": {},
   "source": [
    "- target_modules\n",
    "    - nn.Linear, nn.Embedding and nn.Conv2d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f85aa-3a00-404d-9d0b-c3793746469f",
   "metadata": {},
   "source": [
    "```\n",
    "import re\n",
    "pattern = r'\\((\\w+)\\): Linear'\n",
    "# (norobots): Linear\n",
    "# (sql): Linear\n",
    "# (adcopy): Linear\n",
    "# (merge): Linear\n",
    "linear_layers = re.findall(pattern, str(model.modules))\n",
    "target_modules = list(set(linear_layers))\n",
    "target_modules\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90836ddc-bd98-4266-b2c3-ae18e31936ea",
   "metadata": {},
   "source": [
    "## lora models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d074236-2821-43b6-a007-c5e932c93bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"smangrul/tinyllama_lora_norobots\"\n",
    "device = \"cuda\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f733eba-f08a-497c-a951-54047c433167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'lm_head', 'up_proj', 'v_proj', 'embed_tokens'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c4e19e-eec4-4f02-9e68-f3ddbb4d1d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823abef7-39ea-4bf6-a5d8-6b0bf65aeb53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17873fe9-3a6e-4506-96d1-ffa0e46b341f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57a0f083-5b22-4ef1-b18e-73d67426a62b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86458827-d43a-4555-9f10-ed99dc984ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<pad>',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>assistant',\n",
       " '<|im_start|>system',\n",
       " '<|im_start|>user'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTokenizer.from_pretrained(\"smangrul/tinyllama_lora_norobots\").vocab.keys() - AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\").vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88625893-a6e8-40d0-85c5-cfacf9dd85ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, peft_model_id, adapter_name=\"norobots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b083d389-46a1-461d-85c1-5a22f8a319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_sql\", adapter_name=\"sql\")\n",
    "_ = model.load_adapter(\"smangrul/tinyllama_lora_adcopy\", adapter_name=\"adcopy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d46633a-ab50-404a-bf66-d57d471cedc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norobots': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'lm_head', 'up_proj', 'v_proj', 'embed_tokens'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None),\n",
       " 'sql': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'up_proj', 'v_proj'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None),\n",
       " 'adcopy': LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=8, target_modules={'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'lm_head', 'up_proj', 'v_proj', 'embed_tokens'}, lora_alpha=16, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5576b5b1-9a46-4923-8ec8-9f350a17c119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norobots', 'sql', 'adcopy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.peft_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5ce07a-3c53-45c8-9286-1c9248aef56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots 8 16 2.0 False\n",
      "sql 8 16 2.0 False\n",
      "adcopy 8 16 2.0 False\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.peft_config.items():\n",
    "    print(k, v.r, v.lora_alpha, v.lora_alpha/v.r, v.fan_in_fan_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4360e2-675b-417a-bdde-966b1bef0a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): lora.Embedding(\n",
       "          (base_layer): Embedding(32005, 2048)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (norobots): Dropout(p=0.1, inplace=False)\n",
       "            (adcopy): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "          )\n",
       "          (lora_embedding_B): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "          )\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=2048, out_features=32005, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (norobots): Dropout(p=0.1, inplace=False)\n",
       "          (adcopy): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "          (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (norobots): Linear(in_features=8, out_features=32005, bias=False)\n",
       "          (adcopy): Linear(in_features=8, out_features=32005, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79963fce-44cf-488a-9b3a-81d2effcce04",
   "metadata": {},
   "source": [
    "## merge 3 adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b68847-b8f4-4222-a46e-db1cce3a9293",
   "metadata": {},
   "source": [
    "- combination_type\n",
    "    - [`svd`, `linear`, `cat`, `ties`, `ties_svd`, `dare_ties`, `dare_linear`, `dare_ties_svd`, `dare_linear_svd`, `magnitude_prune`, `magnitude_prune_svd`]\n",
    "    - `combination_type = \"linear\" if len(adapters) == 1 else combination_type`\n",
    "    - 两种主要的类型\n",
    "        - TIES：TrIm, Elect, and Merge (TIES) is a three-step method for merging models. F\n",
    "        - DARE：Drop And REscale is a method that can be used to prepare for other model merging methods like TIES.\n",
    "    - 实现上\n",
    "        -  `cat`\n",
    "        -  `[svd, ties_svd, dare_linear_svd, dare_ties_svd, magnitude_prune_svd]`\n",
    "        -  `[linear, ties, dare_linear, dare_ties, magnitude_prune]`\n",
    "- target\n",
    "    - lora_A/lora_B\n",
    "    - lora_embedding_A/lora_embedding_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c0df65-e87f-4318-8e9d-20ea529264f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adapters = [\"norobots\", \"adcopy\", \"sql\"]\n",
    "weights = [2.0, 0.3, 0.7]\n",
    "adapter_name = \"merge\"\n",
    "density = 0.2\n",
    "# combination_type = \"ties\"\n",
    "combination_type = \"svd\"\n",
    "if adapter_name in model.peft_config:\n",
    "    model.delete_adapter(adapter_name)\n",
    "model.add_weighted_adapter(adapters, weights, adapter_name, combination_type=combination_type, density=density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a17bac1b-3bf5-4597-8ac0-f3bab23c4f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norobots {'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'lm_head', 'up_proj', 'v_proj', 'embed_tokens'}\n",
      "adcopy {'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'lm_head', 'up_proj', 'v_proj', 'embed_tokens'}\n",
      "sql {'down_proj', 'o_proj', 'k_proj', 'gate_proj', 'q_proj', 'up_proj', 'v_proj'}\n"
     ]
    }
   ],
   "source": [
    "for adapter in adapters:\n",
    "    print(adapter, model.peft_config[adapter].target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73962bbc-f61f-4230-9108-4d851dd9c5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): lora.Embedding(\n",
       "          (base_layer): Embedding(32005, 2048)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (norobots): Dropout(p=0.1, inplace=False)\n",
       "            (adcopy): Dropout(p=0.1, inplace=False)\n",
       "            (merge): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "              (merge): Parameter containing: [torch.cuda.FloatTensor of size 8x32005 (GPU 0)]\n",
       "          )\n",
       "          (lora_embedding_B): ParameterDict(\n",
       "              (norobots): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "              (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "              (merge): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (GPU 0)]\n",
       "          )\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-21): 22 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=256, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=5632, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (norobots): Dropout(p=0.1, inplace=False)\n",
       "                  (sql): Dropout(p=0.1, inplace=False)\n",
       "                  (adcopy): Dropout(p=0.1, inplace=False)\n",
       "                  (merge): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (norobots): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (sql): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (adcopy): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                  (merge): Linear(in_features=5632, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (norobots): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (sql): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (adcopy): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                  (merge): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): lora.Linear(\n",
       "        (base_layer): Linear(in_features=2048, out_features=32005, bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (norobots): Dropout(p=0.1, inplace=False)\n",
       "          (adcopy): Dropout(p=0.1, inplace=False)\n",
       "          (merge): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (norobots): Linear(in_features=2048, out_features=8, bias=False)\n",
       "          (adcopy): Linear(in_features=2048, out_features=8, bias=False)\n",
       "          (merge): Linear(in_features=2048, out_features=8, bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (norobots): Linear(in_features=8, out_features=32005, bias=False)\n",
       "          (adcopy): Linear(in_features=8, out_features=32005, bias=False)\n",
       "          (merge): Linear(in_features=8, out_features=32005, bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8acbf6d8-a350-4cf9-96aa-43689421a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.base_model.model.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8478ba0-29ca-47ea-a4ad-3e9fb4731392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'norobots': 2.0, 'adcopy': 2.0, 'merge': 1.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.get_submodule('model.embed_tokens').scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199e2e17-bd12-4d5a-a172-80028ace8ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peft.tuners.lora.bnb.Linear4bit"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model.get_submodule('model.layers.0.self_attn.q_proj'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbe71f-e9b0-4443-ba61-107c650434f0",
   "metadata": {},
   "source": [
    "### from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e7f70c3-7f13-4854-893f-ef639a65352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lora.Embedding(\n",
       "  (base_layer): Embedding(32005, 2048)\n",
       "  (lora_dropout): ModuleDict(\n",
       "    (norobots): Dropout(p=0.1, inplace=False)\n",
       "    (adcopy): Dropout(p=0.1, inplace=False)\n",
       "    (merge): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lora_A): ModuleDict()\n",
       "  (lora_B): ModuleDict()\n",
       "  (lora_embedding_A): ParameterDict(\n",
       "      (norobots): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "      (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 8x32005 (GPU 0)]\n",
       "      (merge): Parameter containing: [torch.cuda.FloatTensor of size 8x32005 (GPU 0)]\n",
       "  )\n",
       "  (lora_embedding_B): ParameterDict(\n",
       "      (norobots): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "      (adcopy): Parameter containing: [torch.cuda.HalfTensor of size 2048x8 (GPU 0)]\n",
       "      (merge): Parameter containing: [torch.cuda.FloatTensor of size 2048x8 (GPU 0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c4461c-679b-4a81-a17c-9861a7b88220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_1 = model.base_model.model.model.embed_tokens.lora_embedding_A['norobots']\n",
    "lora_a_2 = model.base_model.model.model.embed_tokens.lora_embedding_A['adcopy']\n",
    "lora_b_1 = model.base_model.model.model.embed_tokens.lora_embedding_B['norobots']\n",
    "lora_b_2 = model.base_model.model.model.embed_tokens.lora_embedding_B['adcopy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c97186-cb80-4eed-8a98-1f8f7c59be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]),\n",
       " torch.Size([8, 32005]),\n",
       " torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_1.shape, lora_b_1.shape, lora_a_2.shape, lora_b_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eccc2d7-c2ea-4632-8d85-b57bdfe45bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = [2, 2]\n",
    "weights = [2, 0.3] \n",
    "valid_weights = [2*2, 2*0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a8dd3e6-750c-4f3f-8691-206c27e7e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(weight, fan_in_fan_out):\n",
    "    if not fan_in_fan_out:\n",
    "        return weight\n",
    "\n",
    "    if isinstance(weight, torch.nn.Parameter):\n",
    "        return torch.nn.Parameter(weight.T)\n",
    "    return weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579376cd-c1fa-48b6-9daf-9b0bc0c594e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora/layer.py#L450-L482\n",
    "delta_lora_1 = transpose(lora_b_1 @ lora_a_1, True) * scaling[0]\n",
    "delta_lora_2 = transpose(lora_b_2 @ lora_a_2, True) * scaling[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3df74f2-2c09-40ce-8816-8b217a70d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0051,  0.0033,  0.0034,  ...,  0.0007,  0.0063, -0.0040],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0040,  0.0023, -0.0061,  ..., -0.0033, -0.0078, -0.0032],\n",
       "        [-0.0049, -0.0061,  0.0007,  ..., -0.0042, -0.0038,  0.0104],\n",
       "        [ 0.0014,  0.0111, -0.0023,  ..., -0.0019,  0.0016,  0.0091]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb12eb9c-e203-4c8e-9019-abc8c81579d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0098, -0.0076, -0.0048,  ...,  0.0222, -0.0203, -0.0034],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0015,  0.0047, -0.0089,  ..., -0.0164,  0.0086, -0.0184],\n",
       "        [-0.0065, -0.0049, -0.0055,  ..., -0.0001, -0.0073, -0.0074],\n",
       "        [ 0.0045,  0.0220, -0.0076,  ..., -0.0301,  0.0191,  0.0123]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "936ff6a2-6c28-4a35-a892-f93acf0539f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32005, 2048]), torch.Size([32005, 2048]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora_1.shape, delta_lora_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6e780f-9785-48f2-a66e-d83b90f0410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0147,  0.0087,  0.0105,  ...,  0.0161,  0.0129, -0.0181],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-0.0150,  0.0119, -0.0298,  ..., -0.0230, -0.0261, -0.0239],\n",
       "        [-0.0233, -0.0274, -0.0006,  ..., -0.0169, -0.0194,  0.0371],\n",
       "        [ 0.0084,  0.0575, -0.0138,  ..., -0.0258,  0.0178,  0.0437]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_lora = valid_weights[0] * delta_lora_1 + valid_weights[1] * delta_lora_2\n",
    "delta_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b1d76f3-1b6f-4305-ae70-b3b99081fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_lora = delta_lora.T\n",
    "U, S, Vh = torch.linalg.svd(delta_lora.float(), full_matrices=True)\n",
    "U = U[:, :8]\n",
    "S = S[:8]\n",
    "U = U @ torch.diag(S)\n",
    "Vh = Vh[:8, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c872f042-7927-4640-b7ab-f529a1ba9784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]), torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh.shape, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47af37e4-c2fb-4370-aac5-532c5064598e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9250e-08,  3.6710e-03,  5.8551e-09,  ..., -5.5535e-03,\n",
       "         -1.1281e-02, -5.8577e-03],\n",
       "        [-5.3737e-08,  7.6944e-03, -9.9491e-09,  ..., -1.8266e-02,\n",
       "         -2.5229e-02,  5.2019e-03],\n",
       "        [-2.8191e-08, -3.8739e-03, -2.3445e-09,  ..., -2.6179e-03,\n",
       "         -1.5592e-03,  2.8683e-02],\n",
       "        ...,\n",
       "        [ 1.6487e-08, -3.0573e-03, -1.4432e-10,  ...,  9.0157e-03,\n",
       "         -2.2049e-02,  4.6260e-03],\n",
       "        [-2.2342e-08,  1.2938e-02, -5.7639e-09,  ...,  1.6897e-02,\n",
       "          8.5601e-03, -1.1252e-02],\n",
       "        [-1.0293e-08, -4.6255e-03, -2.4660e-08,  ..., -1.4191e-02,\n",
       "          1.2497e-02,  6.5705e-03]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8f45f12-0f99-4ac8-a86a-3da2e843ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_a_new = model.base_model.model.model.embed_tokens.lora_embedding_A['merge']\n",
    "lora_b_new = model.base_model.model.model.embed_tokens.lora_embedding_B['merge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48b7900e-6f8e-4276-b061-0e35b8e7053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 32005]), torch.Size([2048, 8]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_new.shape, lora_b_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b422794-ad4e-48b7-aa80-7372778a9bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 6.6927e-08,  3.6697e-03, -4.0709e-08,  ..., -5.5574e-03,\n",
       "         -1.1279e-02, -5.8365e-03],\n",
       "        [ 5.2394e-08,  7.7513e-03,  3.8410e-08,  ..., -1.8233e-02,\n",
       "         -2.5212e-02,  4.8264e-03],\n",
       "        [-3.8023e-08,  3.7841e-03,  8.6544e-09,  ...,  2.8255e-03,\n",
       "          1.8587e-03, -2.8766e-02],\n",
       "        ...,\n",
       "        [-2.4451e-09, -3.0670e-03, -6.7911e-09,  ...,  8.9840e-03,\n",
       "         -2.2061e-02,  4.7337e-03],\n",
       "        [-3.0357e-08, -1.2936e-02, -3.8171e-09,  ..., -1.6890e-02,\n",
       "         -8.5719e-03,  1.1253e-02],\n",
       "        [ 1.4960e-08, -4.6251e-03,  7.7989e-08,  ..., -1.4207e-02,\n",
       "          1.2501e-02,  6.5824e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_a_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e439c-14e0-4475-ac7a-a52fe8c3d2cc",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23357860-dc1d-4567-88cb-5f7214eaecca",
   "metadata": {},
   "source": [
    "### instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f51c4a9-77a8-47ee-928c-1377f35f629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>user\\nWrite an essay about Generative AI.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Write an essay about Generative AI.\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b181eed-b7c0-498a-9a46-1b3f449e630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|im_start|>user \n",
      "Write an essay about Generative AI.<|im_end|> \n",
      "<|im_start|>assistant \n",
      "Generative Artificial Intelligence (GAI) is a new type of artificial intelligence that uses generative models to create art and other forms of creativity. The goal of GAI is to generate artwork based on prompts or instructions provided by the user, such as \"make this look like a panda\", or \"draw me in the style of Picasso\". This process can be iterated over multiple iterations until the desired result is achieved. For example, if you were given the task of creating a painting inspired by Pablo Picasso's work, then your final product might resemble his famous portrait of Marie-Therese Walter.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "outputs = model.generate(**inputs, max_new_tokens=256, do_sample=True, top_p=0.95, temperature=0.2, repetition_penalty=1.2, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02378e-9264-4da9-b90f-1999cb74e04d",
   "metadata": {},
   "source": [
    "### ad copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7be476fa-89d1-4143-8330-4fe135cb15eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nCreate a text ad given the following product and description.<|im_end|>\\n<|im_start|>user\\nProduct: Sony PS5 PlayStation Console\\nDescription: The PS5 console unleashes new gaming possibilities that you never anticipated.<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Create a text ad given the following product and description.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Product: Sony PS5 PlayStation Console\\nDescription: The PS5 console unleashes new gaming possibilities that you never anticipated.\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14d25e8f-f196-4392-b6af-3228ac373705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|im_start|>system \n",
      "Create a text ad given the following product and description.<|im_end|> \n",
      "<|im_start|>user \n",
      "Product: Sony PS5 PlayStation Console\n",
      "Description: The PS5 console unleashes new gaming possibilities that you never anticipated.<|im_end|> \n",
      "<|im_start|>assistant \n",
      "The PS5 is an exciting new addition to your entertainment system, featuring a sleek design with innovative technologies like Blu-ray Disc playback, WiFi connectivity, and more. It's packed with powerful hardware and software features for immersive gameplay experiences, including dynamic lighting effects, motion controls, and more. With its impressive specs, it will be sure to please gamers of all ages!<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "outputs = model.generate(**inputs, max_new_tokens=256, do_sample=True, top_p=0.95, temperature=0.2, repetition_penalty=1.2, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc78cf-8923-4f97-88b6-dc32979c1dc9",
   "metadata": {},
   "source": [
    "### sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9e303d-7d79-41c9-8539-e3a13277c6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: 2-11365528-2\n",
      "Columns: ['Team', 'Head Coach', 'President', 'Home Ground', 'Location']\n",
      "Natural Query: Who is the Head Coach of the team whose President is Mario Volarevic?\n",
      "SQL Query:\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Table: 2-11365528-2\n",
    "Columns: ['Team', 'Head Coach', 'President', 'Home Ground', 'Location']\n",
    "Natural Query: Who is the Head Coach of the team whose President is Mario Volarevic?\n",
    "SQL Query:\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e6320d6-57a2-49d9-8176-bf5cfb0ab848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Table: 2-11365528-2\n",
      "Columns: ['Team', 'Head Coach', 'President', 'Home Ground', 'Location']\n",
      "Natural Query: Who is the Head Coach of the team whose President is Mario Volarevic?\n",
      "SQL Query: SELECT Team, Head Coach, President, Home Ground FROM Teams WHERE Head Coach = Mario Volarevic\n",
      "Result:\n",
      "Team   Head Coach      President    Home Ground\n",
      "----------------------------------------------\n",
      "Boston Celtics     <NAME>          Boston\n",
      "Chicago Bulls       <NAME>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "outputs = model.generate(**inputs, max_new_tokens=64, repetition_penalty=1.1, eos_token_id=tokenizer(\"</s>\").input_ids[-1])\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fae95b-2bdb-4e0e-a86e-e98ff7a3fc99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
