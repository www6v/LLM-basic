{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd18f0e",
   "metadata": {},
   "source": [
    "- 源码面前，了无秘密\n",
    "    - 学习成熟的框架，提升代码水平\n",
    "    - 后续直接改源码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59c3cf",
   "metadata": {},
   "source": [
    "## type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead9648",
   "metadata": {},
   "source": [
    "\n",
    "- **task_type/model_type**:\n",
    "\n",
    "    \n",
    "    - `LoraConfig(task_type='CAUSAL_LM')`\n",
    "    \n",
    "    ```\n",
    "    MODEL_TYPE_TO_PEFT_MODEL_MAPPING = {\n",
    "        \"SEQ_CLS\": PeftModelForSequenceClassification,\n",
    "        \"SEQ_2_SEQ_LM\": PeftModelForSeq2SeqLM,\n",
    "        \"CAUSAL_LM\": PeftModelForCausalLM,\n",
    "        \"TOKEN_CLS\": PeftModelForTokenClassification,\n",
    "    }\n",
    "    ```\n",
    "\n",
    "- **peft_type**\n",
    "\n",
    "    ```\n",
    "    PEFT_TYPE_TO_MODEL_MAPPING = {\n",
    "        PeftType.LORA: LoraModel,\n",
    "        PeftType.PROMPT_TUNING: PromptEmbedding,\n",
    "        PeftType.P_TUNING: PromptEncoder,\n",
    "        PeftType.PREFIX_TUNING: PrefixEncoder,\n",
    "        PeftType.ADALORA: AdaLoraModel,\n",
    "        PeftType.ADAPTION_PROMPT: AdaptionPromptModel,\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e778c",
   "metadata": {},
   "source": [
    "## `PeftModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b81280",
   "metadata": {},
   "source": [
    "```\n",
    "self.base_model = model\n",
    "self.config = self.base_model.config\n",
    "# adapter_name=\"default\"\n",
    "self.active_adapter = adapter_name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92072af",
   "metadata": {},
   "source": [
    "## LoraConfig 与 LoraModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597cf87e",
   "metadata": {},
   "source": [
    "### LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7989b1e",
   "metadata": {},
   "source": [
    "```\n",
    "@dataclass\n",
    "class LoraConfig(PeftConfig):\n",
    "    r: int = field(default=8, metadata={\"help\": \"Lora attention dimension\"})\n",
    "    target_modules: Optional[Union[List[str], str]]\n",
    "    lora_alpha: int = field(default=None, metadata={\"help\": \"Lora alpha\"})\n",
    "    lora_dropout: float = field(default=None, metadata={\"help\": \"Lora dropout\"})\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf4927",
   "metadata": {},
   "source": [
    "- `target_modules`\n",
    "    - The names of the modules to apply Lora to.\n",
    "    - default: `query_key_value`\n",
    "        - `'transformer.h.0.self_attention.query_key_value'`\n",
    "    - 都意味着一个大矩阵 $W\\in \\mathbb R^{A\\times B}$；\n",
    "    \n",
    "\n",
    "\n",
    "```\n",
    "TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING = {\n",
    "    \"t5\": [\"q\", \"v\"],\n",
    "    \"mt5\": [\"q\", \"v\"],\n",
    "    \"bart\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gpt2\": [\"c_attn\"],\n",
    "    \"bloom\": [\"query_key_value\"],\n",
    "    \"blip-2\": [\"q\", \"v\", \"q_proj\", \"v_proj\"],\n",
    "    \"opt\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gptj\": [\"q_proj\", \"v_proj\"],\n",
    "    \"gpt_neox\": [\"query_key_value\"],\n",
    "    \"gpt_neo\": [\"q_proj\", \"v_proj\"],\n",
    "    \"bert\": [\"query\", \"value\"],\n",
    "    \"roberta\": [\"query\", \"value\"],\n",
    "    \"xlm-roberta\": [\"query\", \"value\"],\n",
    "    \"electra\": [\"query\", \"value\"],\n",
    "    \"deberta-v2\": [\"query_proj\", \"value_proj\"],\n",
    "    \"deberta\": [\"in_proj\"],\n",
    "    \"layoutlm\": [\"query\", \"value\"],\n",
    "    \"llama\": [\"q_proj\", \"v_proj\"],\n",
    "    \"chatglm\": [\"query_key_value\"],\n",
    "}\n",
    "```\n",
    "\n",
    "```\n",
    "key_list = [key for key, _ in self.model.named_modules()]\n",
    "for key in key_list:\n",
    "    if isinstance(lora_config.target_modules, str):\n",
    "        target_module_found = re.fullmatch(lora_config.target_modules, key)\n",
    "    else:\n",
    "        target_module_found = any(key.endswith(target_key) for target_key in lora_config.target_modules)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036d1f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T09:59:47.688553Z",
     "start_time": "2023-05-28T09:59:47.682484Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig \n",
    "config = LoraConfig(\n",
    "    r=16, #low rank\n",
    "    lora_alpha=32, #alpha scaling， scale lora weights/outputs\n",
    "    # target_modules=[\"q_proj\", \"v_proj\"], #if you know the \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\" # set this for CLM or Seq2Seq\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14296ae1",
   "metadata": {},
   "source": [
    "### model => loramodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a29fed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T09:59:01.188294Z",
     "start_time": "2023-05-28T09:59:01.182229Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84862118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T09:59:13.756924Z",
     "start_time": "2023-05-28T09:59:02.819983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6cf09fbfae47c4b0449ada7fb619ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"bigscience/bloom-7b1\", \n",
    "    load_in_8bit=True, \n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "273d87bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:00:01.076341Z",
     "start_time": "2023-05-28T10:00:01.066982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomForCausalLM(\n",
       "  (transformer): BloomModel(\n",
       "    (word_embeddings): Embedding(250880, 4096)\n",
       "    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (h): ModuleList(\n",
       "      (0-29): 30 x BloomBlock(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): BloomAttention(\n",
       "          (query_key_value): Linear8bitLt(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear8bitLt(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): BloomMLP(\n",
       "          (dense_h_to_4h): Linear8bitLt(in_features=4096, out_features=16384, bias=True)\n",
       "          (gelu_impl): BloomGelu()\n",
       "          (dense_4h_to_h): Linear8bitLt(in_features=16384, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0b3c43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T09:59:43.462611Z",
     "start_time": "2023-05-28T09:59:43.459193Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33a17ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:00:22.227831Z",
     "start_time": "2023-05-28T10:00:13.130737Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fed099b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:00:26.726902Z",
     "start_time": "2023-05-28T10:00:26.718443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BloomForCausalLM(\n",
       "      (transformer): BloomModel(\n",
       "        (word_embeddings): Embedding(250880, 4096)\n",
       "        (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (h): ModuleList(\n",
       "          (0-29): 30 x BloomBlock(\n",
       "            (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (self_attention): BloomAttention(\n",
       "              (query_key_value): Linear8bitLt(\n",
       "                in_features=4096, out_features=12288, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (dense): Linear8bitLt(in_features=4096, out_features=4096, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): BloomMLP(\n",
       "              (dense_h_to_4h): Linear8bitLt(in_features=4096, out_features=16384, bias=True)\n",
       "              (gelu_impl): BloomGelu()\n",
       "              (dense_4h_to_h): Linear8bitLt(in_features=16384, out_features=4096, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507e4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
