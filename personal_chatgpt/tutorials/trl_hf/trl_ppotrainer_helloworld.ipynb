{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fe16cf4-1248-44a9-8d7f-1a3100c90d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['NCCL_P2P_DISABLE'] = '1'\n",
    "os.environ['NCCL_IB_DISABLE'] = '1'\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d20e65-03d9-4239-98c3-34eb7e71cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.0.1 with CUDA 1108 (you have 2.2.2+cu121)\n",
      "    Python  3.10.13 (you have 3.10.13)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-25 18:28:16,128] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7637d319-f864-41f5-9bb0-643b92d460e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export NCCL_P2P_DISABLE=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0f5e6-ccbd-4da7-98ab-a25a969c7a80",
   "metadata": {},
   "source": [
    "## overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fbd00-10d7-4637-82f5-682c2979485b",
   "metadata": {},
   "source": [
    "- https://github.com/huggingface/trl/blob/main/examples/hello_world.py\n",
    "- OpenRLHF: https://github.com/OpenLLMAI/OpenRLHF\n",
    "    - https://arxiv.org/abs/2405.11143\n",
    "- PPO-penalty（PPO1）\n",
    "  \n",
    "    $$\n",
    "    \\begin{split}\n",
    "    &J^{\\theta'}_{PPO}=J^{\\theta'}(\\theta)-\\beta KL(\\theta,\\theta'),\\quad J^{\\theta'}(\\theta)=\\mathbb E_{s_t,a_t\\sim \\pi_{\\theta'}}\\left[\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta'}(a_t|s_t)}A^{\\theta'}(s_t,a_t)\\right]\\\\\n",
    "    &\\mathcal{L}^{\\text{PENALTY}}(\\theta) = \\mathbb{E}_t \\left[ \\hat{A}_t \\frac{\\pi_\\theta(a_t | s_t)}{\\pi_{\\theta_{\\text{old}}}(a_t | s_t)} - \\beta D_{KL} \\left( \\pi_{\\theta_{\\text{old}}}(\\cdot | s_t) \\parallel \\pi_\\theta(\\cdot | s_t) \\right) \\right]\n",
    "    \\end{split}\n",
    "    $$\n",
    "\n",
    "- PPO-clip（PPO2）\n",
    "\n",
    "    $$\n",
    "    J_{PPO2}^{\\theta^k}(\\theta) \\approx \\sum_{(s_t, a_t)} \\min \\left( \\frac{p_\\theta(a_t | s_t)}{p_{\\theta^k}(a_t | s_t)} A^{\\theta^k}(s_t, a_t), \\ \n",
    "    \\text{clip} \\left( \\frac{p_\\theta(a_t | s_t)}{p_{\\theta^k}(a_t | s_t)}, 1 - \\epsilon, 1 + \\epsilon \\right) A^{\\theta^k}(s_t, a_t) \\right)\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d70a5ef-8378-4bae-9e46-0f3ac967600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../imgs/openrlhf.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../imgs/openrlhf.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ad753-b11e-48a0-99ce-9273ced105b1",
   "metadata": {},
   "source": [
    "## model vs. model_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6ef8e80-57fd-4640-98e3-b49b9c867529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load a pretrained model\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18709a59-62ad-4e55-9768-8dd27aac4faf",
   "metadata": {},
   "source": [
    "- `AutoModelForCausalLMWithValueHead`\n",
    "    - `ValueHead`:  `self.summary = nn.Linear(hidden_size, 1)` (hidden_size => 1)\n",
    "        - `value = self.v_head(last_hidden_state).squeeze(-1)`\n",
    "- `model` vs. `model_ref`\n",
    "    - `model`: $\\pi_\\theta$, `model_ref`: $\\pi_{\\theta_{old}}$（$\\pi_{\\text{sft}}$）\n",
    "- `AdaptiveKLController`（https://arxiv.org/pdf/1909.08593）\n",
    "    - 如下公式所示，$\\pi_t, \\rho$ 分别表示新旧策略，与 KL_target 的偏差在 -0.2 到 0.2 之间\n",
    "    - log-space controller\n",
    "\n",
    "    $$\n",
    "    \\log\\beta_{t+1}=\\log\\beta_t+\\log(1+K_\\beta e_t)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d962e94-d770-449d-bbc8-c6494300925d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../imgs/adap_kl_coef.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../imgs/adap_kl_coef.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93a288bf-7147-4cf5-adce-a5b3a7a528c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f28002-d50c-4b14-aaff-e096566d215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b067db7e-db7a-43b5-b931-2faca7265432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "print(tokenizer.pad_token, tokenizer.eos_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4822dc1a-2110-4c1a-967b-9da302bfb94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('<|endoftext|>'))\n",
    "print(tokenizer.decode(tokenizer.encode('<|endoftext|>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f95cde0-e1aa-44dc-80bf-1ef3660950d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1d705d-b7bc-4fd5-9e18-33b3c8d32b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:257: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2. initialize trainer\n",
    "ppo_config = {\"mini_batch_size\": 1, \"batch_size\": 1}\n",
    "config = PPOConfig(**ppo_config)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c4bf26-06a3-4314-9e35-fe068382f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, ... = self.accelerator.prepare(model, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5353de90-871b-4e1b-88fd-b149b8dee371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(model.pretrained_model.device)\n",
    "print(model_ref.pretrained_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8977d1b-c9fa-40d4-b36a-5dc2bbc3f5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1212, 3329,  314, 1816,  284,  262,  220]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. encode a query\n",
    "query_txt = \"This morning I went to the \"\n",
    "query_tensor = tokenizer.encode(query_txt, return_tensors=\"pt\").to(model.pretrained_model.device)\n",
    "query_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f63f0b6-3011-4b3e-ba75-27f228be9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. generate model response\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338d94d-242d-42b3-8e35-6865aa482360",
   "metadata": {},
   "source": [
    "## `ppo_trainer.generate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7d98e73-e09a-43bc-8d6e-6fed0876d9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1212, 3329,  314, 1816,  284,  262,  220], device='cuda:0')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(query_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea29ab87-4db0-49ab-9fb8-dbb4a335136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_tensor = ppo_trainer.generate(list(query_tensor), return_prompt=False, **generation_kwargs)\n",
    "response_txt = tokenizer.decode(response_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b143c7-faef-4115-a4f2-3a98dff8a320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vernacular and found myself at a bar, cook, with a wife. Buggas together in'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f2a4c6-e086-414e-b400-b45887e87ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This morning I went to the \\xa0Budweiser looking for health info checks for the Tick tell check and noticed \"...!...\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.decode(model.generate(\n",
    "#     input_ids=query_tensor,\n",
    "#     **generation_kwargs\n",
    "# )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67c370a-9303-4df7-b5bb-3ef751098879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. define a reward for response\n",
    "# (this could be any reward such as human feedback or output from another model)\n",
    "reward = [torch.tensor(1.0, device=model.pretrained_model.device)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926222a3-f8de-4c7c-ae68-9dd6bf75215e",
   "metadata": {},
   "source": [
    "## `ppo_trainer.step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a3face7-79e7-4474-9651-9f19153066aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1275: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  std_scores = data[\"scores\"].std()\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1302: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stats[\"tokens/queries_len_std\"] = torch.std(query_lens).cpu().numpy().item()\n",
      "/home/whaow/anaconda3/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:1305: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stats[\"tokens/responses_len_std\"] = torch.std(response_lens).cpu().numpy().item()\n"
     ]
    }
   ],
   "source": [
    "train_stats = ppo_trainer.step(queries=[query_tensor[0]], \n",
    "                               responses=[response_tensor[0]], \n",
    "                               scores=reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ff37a-be39-4842-a6f1-3502d0b5362b",
   "metadata": {},
   "source": [
    "```\n",
    "def step(\n",
    "        self,\n",
    "        queries: List[torch.LongTensor],\n",
    "        responses: List[torch.LongTensor],\n",
    "        scores: List[torch.FloatTensor],\n",
    "        response_masks: Optional[List[torch.LongTensor]] = None,\n",
    "    ):\n",
    "\n",
    "    all_logprobs, logits_or_none, values, masks = self.batched_forward_pass(\n",
    "                    self.model,\n",
    "                    queries,\n",
    "                    responses,\n",
    "                    model_inputs,\n",
    "```\n",
    "\n",
    "- `input_ids = [torch.cat([q, r]) for q, r in zip(queries, responses)]`：拼接 queries & responses；\n",
    "- `ppo_trainer.batched_forward_pass`\n",
    "    - logprobs: $\\log\\pi_\\theta(a_t|s_t)$\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "# ppo_trainer.batched_forward_pass\n",
    "# logits.shape == (1, 27, 50257), values.shape == (1, 27)\n",
    "logits, _, values = model(**input_kwargs)\n",
    "\n",
    "# shift labels, next token predicition\n",
    "# lopprobs.shape == (1, 26)\n",
    "logprobs = logprobs_from_logits(logits[:, :-1, :], input_ids[:, 1:])\n",
    "```\n",
    "\n",
    "- 同样地对于 model_ref 再算一遍\n",
    "\n",
    "    ```\n",
    "    ref_logprobs, ref_logits_or_none, _, _ = self.batched_forward_pass(\n",
    "                        self.model if self.is_peft_model else self.ref_model,\n",
    "                        queries,\n",
    "                        responses,\n",
    "                        model_inputs,\n",
    "    ```\n",
    "\n",
    "- 计算 rewards\n",
    "\n",
    "    ```\n",
    "    rewards, non_score_reward, kls = self.compute_rewards(scores, all_logprobs, ref_logprobs, masks)\n",
    "    ```\n",
    "\n",
    "    - kl-penalty\n",
    "    \n",
    "        $$\n",
    "        \\text{KL}_{\\text{penalty}} =\\log\\frac{\\pi_{\\theta}(a_t|s_t)}{\\pi_{\\theta_{\\text{ref}}}(a_t|s_t)}=\\log \\pi_{\\theta}(a_t|s_t) - \\log \\pi_{\\theta_{\\text{ref}}}(a_t|s_t)\n",
    "        $$\n",
    "     - `-self.kl_ctl.value * kl`\n",
    "     - reward is Preference Model (external RM) score + KL penalty\n",
    "- values, advantages, returns = self.compute_advantages(values, rewards, masks)\n",
    "    - `delta = rewards[:, t] + self.config.gamma * nextvalues - values[:, t]`\n",
    "        \n",
    "        $$\n",
    "        \\delta_t = r_t + \\gamma V(s_{t+1}) - V(s_t)\n",
    "        $$\n",
    "    - gae lam (`lastgaelam = delta + self.config.gamma * self.config.lam * lastgaelam`)\n",
    "\n",
    "        $$\n",
    "        \\hat{A_t} = \\delta_t + \\gamma \\lambda \\hat{A_{t+1}}\n",
    "        $$\n",
    "    - `returns = advantages + values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a06c8d97-5bde-4f09-ade5-02001bed9394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../../imgs/trl_ppo_loss.png\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='../../imgs/trl_ppo_loss.png', width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfae7d8-c5e5-40aa-ad46-38e3fce877dd",
   "metadata": {},
   "source": [
    "- `ratio = torch.exp(logprobs - old_logprobs)`\n",
    "\n",
    "$$\n",
    "\\exp(\\log\\pi_\\theta-\\log\\pi_{\\theta_{old}})=\\exp\\left(\\log\\frac{\\pi_\\theta}{\\pi_{\\theta_{old}}}\\right)=\\frac{\\pi_\\theta}{\\pi_{\\theta_{old}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48ade59b-1c66-49b1-90c9-22e6ad02c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective/kl\n",
      "objective/kl_dist\n",
      "objective/logprobs\n",
      "objective/ref_logprobs\n",
      "objective/kl_coef\n",
      "objective/entropy\n",
      "ppo/mean_non_score_reward\n",
      "ppo/mean_scores\n",
      "ppo/std_scores\n",
      "tokens/queries_len_mean\n",
      "tokens/queries_len_std\n",
      "tokens/queries_dist\n",
      "tokens/responses_len_mean\n",
      "tokens/responses_len_std\n",
      "tokens/responses_dist\n",
      "ppo/loss/policy\n",
      "ppo/loss/value\n",
      "ppo/loss/total\n",
      "ppo/policy/entropy\n",
      "ppo/policy/approxkl\n",
      "ppo/policy/policykl\n",
      "ppo/policy/clipfrac\n",
      "ppo/policy/advantages\n",
      "ppo/policy/advantages_mean\n",
      "ppo/policy/ratio\n",
      "ppo/returns/mean\n",
      "ppo/returns/var\n",
      "ppo/val/vpred\n",
      "ppo/val/error\n",
      "ppo/val/clipfrac\n",
      "ppo/val/mean\n",
      "ppo/val/var\n",
      "ppo/val/var_explained\n",
      "ppo/learning_rate\n",
      "time/ppo/forward_pass\n",
      "time/ppo/compute_rewards\n",
      "time/ppo/compute_advantages\n",
      "time/ppo/optimize_step\n",
      "time/ppo/calc_stats\n",
      "time/ppo/total\n"
     ]
    }
   ],
   "source": [
    "for key in train_stats.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d9044-85ac-46bc-ad43-61e0c05792a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
