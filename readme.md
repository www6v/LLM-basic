# LLM-basic
## Pytorch
+ core

## Transformer
+ MoE
+ SFT

## RL
+ PPO
+ GRPO
+ DPO

## DeepSeek
### R1
+ pre-train
  - GRPO 
    R1-zero like recurrent from scratch on Qwen 

+ post-training
  - SFT for R1
  - Distill for R1[黑盒]


### V3
+ DeepSeek-V3 MoE from scratch  

+ MTP
  - MTP on Qwen

+ MLA  

### Knowledge Distillation
+ [白盒]


